\documentclass[../../lecture_notes.tex]{subfiles}

\begin{document}

\noindent The core of programming languages comes down to 3 things: 
\begin{enumerate}[itemsep=0mm]
	\item principles and limitations of programming models
	\item notations and user supports for programming models
	\item methods of evaluation of programming models
\end{enumerate}
These are the things we consider when attempting to decide on a choice of notation.\\
By the end of the course, our choices will be:\\
	\indent Ocaml -- our canonical functional language\\
	\indent Java -- our canonical imperative language\\
	\indent Prolog -- our canonical logic language\\
These are our "big three" languages, which cover the main paradigms. \\
We will also cover Scheme, Python, etc. \\
\\
The general goal is to learn, evaluate, and use languages.\\
How do we evaluate a language? We seek to minimize costs.\\
These come in the form of: \begin{enumerate}[itemsep=0mm]
	\item Primary Costs 
		\begin{enumerate}[itemsep=0mm]
			\item \underline{maintainability}
			\item \underline{reliability}
			\item \underline{training}
			\item \underline{program development}
		\end{enumerate}
	\item Secondary Costs
		\begin{enumerate}[itemsep=0mm]
			\item \underline{execution overhead (exception: critical in machine learning)}
			\item \underline{licensing fees}
			\item \underline{build/compilation overhead}
			\item \underline{porting overhead}
		\end{enumerate}
\end{enumerate} These choices can often be political (Apple vs Google, etc).\\
\\
The main issues of language design, on the other hand, are: \begin{enumerate}[itemsep=0mm]
	\item \underline{orthogonality}\\
		For example, all C types except arrays are returnable, which presents difficulties with typedef!
	\item \underline{(runtime) efficiency}\\
		This includes CPU, RAM, energy, network access, etc.
	\item \underline{simplicity}
	\item \underline{convenience}\\
		C allows {i++, ++i, i = i + 1, i += 1}, choosing convenience over simplicity.
	\item \underline{safety}\\
		Errors can be checked in two ways:\begin{enumerate}[itemsep=0mm]
			\item static checking -- safe, compile-time checking
			\item dynamic checking -- simple, runtime checking
		\end{enumerate}
	\item \underline{abstraction support}
	\item \underline{exceptions}
	\item \underline{concurrency}
	\item \underline{evolution/mutability}\\
		"As long as a language is alive, it is mutating"
\end{enumerate} \medskip

We will now move on to considering more computer language specific issues.\\
The translation of a language's code goes as follows:
\begin{center} \begin{tikzpicture} [sibling distance = 5em,]
	\node[rectangle, draw] (text) {int main(void) \{return !getchar();\}};
	\node[rectangle, draw, below =of text.west, anchor=west] (tokens) {
		\begin{tabular} { c | c | c | c | c | c | c | c | c | c | c | c | c }
			int & ID & ( & VOID & ) & \{ & RET & ! & ID & ( & ) & ; & \}
		\end{tabular}};
	\node[ellipse, draw, below =of tokens] (tree) {program}
		child {node [ellipse, draw] {function definition}
			child {node [ellipse, draw, align=center] {return\\type}
				child {node [rectangle, draw] {INT}
					edge from parent node {}
				}
			}
			child {node [rectangle, draw] {ID}
				edge from parent node{}
			}
			child {node [rectangle, draw] {(}
				edge from parent node{}
			}
			child {node [ellipse, draw] {args}
				child {node [rectangle, draw] {VOID}
					edge from parent node{}
				}
				edge from parent node{}
			}
			child {node [rectangle, draw] {)}
				edge from parent node{}
			}
			child {node [rectangle, draw] {\{}
				edge from parent node{}
			}
			child {node [ellipse, draw] {statement}
				child {node [ellipse, draw] {RET Statement}
					child {node [rectangle, draw] {RET}
						edge from parent node{}
					}
					child {node [ellipse, draw] {expr}
						child {node [rectangle, draw] {!}
							edge from parent node{}
						}
						child {node [ellipse, draw] {expr}
							child {node [rectangle, draw] {call}
								child {node [ellipse, draw] {expr}
									child {node [rectangle, draw] {ID}
										edge from parent node{}
									}
									edge from parent node{}
								}
								child {node [rectangle, draw] {(}
									edge from parent node{}
								}
								child {node [ellipse, draw] {params}
									child {node {}
										edge from parent node{}
									}
									edge from parent node{}
								}
								child {node [rectangle, draw] {)}
									edge from parent node{}
								}
								child {node [rectangle, draw] {;}
									edge from parent node{}
								}
								edge from parent node{}
							}
							edge from parent node{}
						}
						edge from parent node{}
					}
					edge from parent node{}
				}
				edge from parent node{}
			}
			child {node [rectangle, draw] {\}}
				edge from parent node {}
			}
			edge from parent node {}
		};
	\draw [->] (text.south west) to [out=210, in=120] node [align=center, left] {lexical\\analysis} (tokens.north west);
	\draw [->] (tokens.south west) to [out=210, in=120] node [align=center, below] {parsing} (tree.north west);
\end{tikzpicture} \end{center}
We use this tree to build our compiler-level code.\\
It is portable and convenient for the compiler creator.\\
This puts the code $\to$ run process as: 
\begin{center} \begin{tikzpicture}
	\node[circle, draw, align=center, anchor=west,] (1) {High-\\Level\\Code};
	\node[circle, draw, right =of 1] (2) {Tokens};
	\node[circle, draw, right =of 2, align=center] (3) {Parse\\Tree};
	\node[circle, draw, right=of 3, align=center] (4) {Comp.\\Code};
	\node[circle, draw, below =of 1, align=center] (5) {Mach.\\Code};
	\node[circle, draw, right =of 5, align=center] (6) {Obj.\\Code};
	\node[circle, draw, right =of 6] (7) {a.out};
	\node[circle, draw, right =of 7] (8) {run};
	\draw [->] (1.east) -- node [align=center] {lex.\\anal.} (2.west);
	\draw [->] (2.east) -- node [align=center, above] {parse} (3.west);
	\draw [->] (3.east) -- (4.west);
	\draw [->] (4.south west) --  (5.north east);
	\draw [->] (5.east) -- node [align=center, above] {asm.} (6.west);
	\draw [->] (6.east) -- node [align=center, above] {ld.} (7.west);
	\draw [->] (7.east) --  node [align=center, above] {load} (8.west);
\end{tikzpicture} \end{center} 

Our first two assignments focus on the token $\to$ tree step. \\
This is where we consider \textbf{\underline{syntax}}

\subsection*{Syntax}
$\equiv$ the form of a language independent of meaning/\textbf{\underline{semantics}}
\begin{itemize}[itemsep=0mm]
	\item a sentence can have good syntax and bad semantics\\
		"Colorless green ideas sleep furiously." -- Noam Chomsky
	\item a sentence can have good semantics and bad syntax\\
		"Ireland has Leprechauns galore." -- Paul Eggert
	\item a sentence can be syntactically or semantically ambiguous\\
		"Time flies." -- unknown; probably a politician, since doublespeak helps them
\end{itemize}

\noindent How do we evaluate a syntax?  \\
Consider the example of 3+4*5 (C) vs 345*+ (Forth) vs (+3(* 4 5)) (LISP)
\begin{itemize} [itemsep=0mm]
	\item \underline{inertia} -- no one likes to have to change\\
		C > Forth $\approx$ Lisp, since C is familiar to standard form
	\item \underline{simplicity/regularity} -- few, regularly applied rules\\
		Forth (never parentheses) > LISP (always parentheses) > C (some parentheses)
	\item \underline{human readability} -- code shows algorithm/operations
		C $\equiv$ LISP $\equiv$ Forth due to \underline{Leibniz's Criteria} \\
		$\equiv$ a proposition's form should reflect reality\\
				ex. "if (0 < x \&\& x < n)" > "if (x > 0 \&\& x < n)" since 0 < x < n is natural
	\item \underline{human writability}\\
		C  > LISP $\approx$ Forth due to comfortability with standard form
	\item \underline{redundancy} -- repetition helps catch errors (inapplicable in this example)
	\item \underline{unambiguity} -- code has only one interpretation\\
		Forth $\equiv$ LISP > C, since C relies on an implicit order of operations
\end{itemize}
Syntax is build upon \textbf{\underline{tokens}}
\subsection*{Tokens}
Tokens are a subset of \textbf{\underline{lexemes}}, which are built from characters.\\
Tokens can be broken up into three categories \begin{itemize}[itemsep=0mm]
	\item \underline{identifiers} 
	\item \underline{operators} \\
		Operators are often user-defined, but some are \textbf{\underline{keywords}}\\
		\indent keyword $\equiv$ a word with a special meaning in a language\\
		Some operators can also be categorized as \textbf{\underline{reserved words}}\\
		\indent reserved word $\equiv$ words which are not allowed to be used as a name\\
		C, for example, has reserved all words of the form $\_[[:\mbox{capital}:]].*$.\\
		This is annoying, since it makes us use \_Noreturn instead of noreturn.\\
		Consider the example 'if':\\
			'if' is a keyword since it tests an expression, BUT: \begin{itemize}[itemsep=0mm]
			\item in C it is reserved, $\implies$ 'int if = 12' is invalid\\
			\item in PL1 it is not reserved, $\implies$ 'if (if=3) if = 4' is valid.
			\end{itemize}
	\item \underline{numbers} \\
		This includes 27, 0x19, and 5e-12, but not -127, because itemizers are greedy.\\
		To understand this, consider the example: a - - - - - b; this should be valid as (a - -) - (- - b), 
		\\ BUT the tokenizer reads it as ((a - - ) - - ) - b, and we cannot decrement a constant.
\end{itemize}
It may be a natural assumption that tokens may only consist of characters, but this is overkill.\\
We must consider both white space, and ambiguities like 'ifx', which would cause slow parsing.\\
Luckily, tokens are a level higher than that, and can thus be parsed with C.

\subsection*{Grammars}
\noindent If we were attempting to define a language in mathematical form, we may do it like so:
	\begin{center} $L = [a^m b^n | m < n]$, tokens: {a, b} \end{center}
This would give us the language {"", "b", "ab", "abb", ...}\\
This doesn't scale well to programming languages.  Instead we abstract to \textbf{\underline{grammars}}\\
\\
A few definitions are necessary to begin this discussion:\\
\indent \textbf{\underline{grammar}} $\equiv$ a description of a language's syntax\\
\indent \indent  \textbf{\underline{language}} $\equiv$ a set of sentences\\
\indent \indent  \textbf{\underline{sentence}} $\equiv$ a string within a language\\
\indent \indent  \textbf{\underline{string}} $\equiv$ a finite sequence of tokens\\
The specific grammars in this course are called \textbf{\underline{Context-Free Grammars}}\\
A CFG is a set containing \begin{itemize} [itemsep=0mm]
	\item a finite set of tokens/terminal symbols (leaves)
	\item a finite set of non-terminal symbols (intermediate nodes)
	\item a finite set of rules (parent/child relationships)
	\item a start symbol (root)
\end{itemize}
Thus they can be defined by a grammar trees like the above.\\
They are called "context free" because an expression's definition is free of its context.\\
For clarity, consider a few counterexamples:\\
\indent in C, 'typedef int foo; ... foo i;' is valid, but 'foo i;' is not.\\
\indent in Python, 'if (true) pass' is invalid due to indentation rules.
\end{document}