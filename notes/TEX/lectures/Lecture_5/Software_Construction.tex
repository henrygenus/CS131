\documentclass[../../lecture_notes.tex]{subfiles}

\begin{document}

\noindent There are a few main approaches to running code:
\subsubsection*{The Compiler Model}
think: C, C++, Fortran, etc.\\
gcc's process takes c source code, and runs like so: \begin{enumerate} [itemsep=0mm]
	\item Preprocessing
		\begin{enumerate} [itemsep=0mm]
			\item lexing $\rightarrow$ tokens
			\item parsing $\rightarrow$ parse tree
			\item checking (identifiers, type) $\rightarrow$ checked parse tree
			\item Machine Independent Code generation $\rightarrow$ MIC
			\item optimization $\rightarrow$ optimized intermediate MIC
		\end{enumerate}
	\item Compilation
		\begin{enumerate} [itemsep=0mm]
			\item machine code generation $\rightarrow$ machine dependent code
			\item optimization $\rightarrow$ assembly language
		\end{enumerate}
	\item Assembly
		\begin{enumerate} [itemsep=0mm]
			\item assembly $\rightarrow$ machine code (.o)
		\end{enumerate}
	\item Linking
		\begin{enumerate} [itemsep=0mm]
			\item linking (ld) $\rightarrow$ a.out
		\end{enumerate}
	\item Running
		\begin{enumerate} [itemsep=0mm]
			\item loading by kernel $\rightarrow$ run
		\end{enumerate} 
	\end{enumerate}
Each of these steps can be broken into a separate program using gcc options and tools.\\
Compilers can make programs quite difficult to debug, since code is translated away from the source code.\\
For instance, consider the following two translations:\\
	\indent i *= 2 $\rightarrow$ shl \%rax\\
	\indent 1 = a/b; r = a \% b; $\rightarrow$ ldivq \%rdl\\
By the above, it can be seen that some translations are more direct than others.\\
The transformations compilers can perform include: \begin{itemize} [itemsep=0mm]
	\item aggregation of multiple lines of source code into one machine instructions
	\item splitting of a line of source code into multiple machine instructions
	\item swapping the order of machine commands
\end {itemize}
Since debugging machine code can be incredibly difficult, we developed:\\

\subsubsection*{The Interpreter Model}
The program is left in a form near to the source code and interpreted/run directly.\\
The form of the code is designed for an abstract machine and human-readable.\\
Code is checked prior to translation.\\
The interpreter is written in a high-level language and thus easy to implement.\\
\\
As we can see, interpreters have many advantages over compilers, so why do we use compilers?\\
When running code, an interpreter must walk through a tree or load bytes from MIC.\\
This can result in up to 10 machine instructions for each line of source code.\\
In practice, much of this is optimized away, but the principle stands; we wish to improve this.\\

\subsubsection*{Integrated Development Environment}
think: Eclipse, Emacs, etc.\\
The original was Smalltalk by Xerox, which:
	\begin{itemize} [itemsep=0mm]
		\item handles dependencies and partial recompilation
		\item keeps "one big happy program", including:
			\begin{itemize} [itemsep=0mm]
				\item memory management
				\item exception handling
				\item dumping core
				\item parallelism
			\end{itemize}
		\item interacts with and controls the screen, keyboard, and mouse
		\item reads and works either directly from source code, or from a form very close to it, which allows
			\begin{itemize} [itemsep=0mm]
				\item direct debugging of source code
				\item continuous execution of program while editing
			\end{itemize}
		\end{itemize}

\subsubsection*{Java Virtual Machine (JVM)}
The gjc model is as follows:\\
\begin{tikzpicture}
	\node[ellipse, draw] (src) {foo.java};
	\node[ellipse, draw, right =of src] (cls) {foo.class};
	\node[ellipse, draw, align=center, right =of cls] (int) {Java\\Interpreter};
	\node[rectangle, draw, align=center, right =of int] (comp) {\\Javaint.c\\bytecode-to-x86.c\\};
	\draw [->] (src.east) -- node [align=center, above] {javac} (cls.west);
	\draw [->] (cls.east) -- (int.west);
	\draw [->] (comp.west) -- node [align=center, above] {gcc} (int.east);
\end{tikzpicture} \medskip
\noindent The steps \begin{itemize} [itemsep=0mm]
	\item the interpreter uses bytecode-to-x86.c to \underline{profile} the code\\
		$\equiv$ the compilation of recorded hotspots to machine code
	\item jump to machine code rather than fetching interpreted instructions
	\item progressively compile learned hot spots that pop up during execution
	\end{itemize}
In a sense, the profiler acts like the backend of a compiler.
This has a few advantages: \begin{itemize} [itemsep=0mm]
	\item space -- shared code need only be stored once rather than once per program
	\item time -- recompilation is not necessary on change of source code
	\item space -- unused parts of the library are not unnecessarily loaded
	\end{itemize}
This is called a \textbf{\underline{just-in-time/hotspot compiler}}.\\

\subsubsection*{Conclusion}
Real life is unsurprisingly more complicated; this behavior exists on a spectrum: 
	\begin{itemize} [itemsep=0mm]
		\item pure interpreter -- the intermediate language IS the source code
		\item tokenization -- whitespace and comments are removed (the most common level)
		\item partial compilation --- intermediate code could either be compiled or run directly on an interpreter
		\item full compilation -- code is fully compiled; the intermediate code is machine code
		\end{itemize}
Emacs and eclipse both fall somewhere in the middle of this spectrum.\\
The JVM approach is used for Javascript on browsers, which requires varying code by machine.\\
	\indent This is no big deal -- we already needed different machine code anyway.\\
\\
IDE's and Virtual Machines require one more functionality: \textbf{\underline{Dynamic Linking}}\\
\indent We take a piece of a program/file and link it into a running program. \\
Examples include: \begin{itemize} [itemsep=0mm]
		\item emacs takes shared machine code object files and links it using emacs Lisp
		\item JVM and Javascript do the same thing with their own native methods
	\end{itemize}
In effect, this creates self modifying code, which is an idea fundamental to CS! (See: AI, the stack, etc.)\\
There are two ways to dynamically link:
	\begin{enumerate} [itemsep=0mm]
		\item complete linkage on load time\\
			This is safe, but much slower.
		\item load functions on usage\\
			This can be risky, since \begin{enumerate} [itemsep=0mm]
					\item functions may change between calls
					\item malicious or bad code may cause errors
				\end{enumerate}
		\end{enumerate}
Ideally, we would like the power of self modifying code without the risk.
\\
This class's focus so far has been on imperative languages, which are command execution based.\\
Our attempt to improve dynamic linking is by using functional languages.\\
	\indent There are based in evaluation of expressions.\\
	\indent These avoid the side effects and cache invalidation of imperative languages.\\
This gives us the advantage of building a program on the fly, without the dangers of dynamic linking!

\end{document}